# -*- coding: utf-8 -*-
"""Prophet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15ocrV_0Gbvf7uN4PtQX9Abx4WLvaMs_q
"""

!pip install -q auto-ts

from auto_ts import auto_timeseries

import pandas as pd
ps_data=pd.read_csv("data.csv",sep=";")
ps_data = ps_data[["Date","Case"]]
ps_data["Case"]=ps_data["Case"].diff()
ps_data["Case"].fillna(1,inplace=True)
ps_data["Case"]=ps_data["Case"].astype(int)
date_column= "Date"
pred_column="Case"
ps_data[date_column]=pd.to_datetime(ps_data[date_column])
ps_data.set_index('Date', inplace=True)
ps_data.info()

ps_data.head()

import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose

# Decompose the 'Case' time series
decomposition = seasonal_decompose(ps_data['Case'], model='additive')

# Plot the decomposed components
decomposition.plot().suptitle('Time Series Decomposition of Case Data')

import numpy as np

residuals = decomposition.resid.dropna()  # Removing NaN values which are a result of the decomposition
z_scores = np.abs((residuals - residuals.mean()) / residuals.std())

threshold = 3
anomalies = residuals[z_scores > threshold]

# Replace anomalies with the median value of 'Case'
median_value = ps_data['Case'].median()
ps_data.loc[anomalies.index, 'Case'] = median_value

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 7))
plt.plot(ps_data.index, ps_data['Case'].interpolate(), color='blue', linestyle='--')
plt.title('Interpolated Case Data')
plt.xlabel('Date')
plt.ylabel('Case')
plt.legend()
plt.show()

test_df= ps_data[-7:]

ps_data.reset_index(inplace=True)

ps_data.head()
ps_data.info()

ps_data.tail()

date_column= "Date"
pred_column="Case"
ps_data[date_column]=pd.to_datetime(ps_data[date_column])
ps_data = ps_data.sort_values('Date')
ps_data.tail()

train_df= ps_data.iloc[:-7]
test_df= ps_data.iloc[-7:]

test_df

train_df.Case.plot(figsize=(15,8),title=pred_column,fontsize=14,label="Train")
test_df.Case.plot(figsize=(15,8),title=pred_column,fontsize=14,label="Test")
plt.legend()
plt.grid()
plt.show()

model= auto_timeseries(forecast_period=7,score_type="rmse",time_interval="D",model_type="best")
model.fit(traindata=train_df,ts_column= date_column,target=pred_column)

model.get_leaderboard()

future_predictions=model.predict(7,model="Prophet")

future_predictions

future_predictions= future_predictions[["ds","yhat"]]

future_predictions["ds"]=pd.to_datetime(future_predictions["ds"])
future_predictions.set_index('ds', inplace=True)

future_predictions

print(test_df)

test_df

ps_data[date_column]=pd.to_datetime(ps_data[date_column])
ps_data.set_index('Date', inplace=True)

test_df= ps_data[-7:]

future_predictions["yhat"].plot(figsize=(14,5),title=pred_column,fontsize=14,label="Forecast")
test_df[pred_column].plot(figsize=(14,5),title="Actual vs Forecast Values",fontsize=14,label="Test")
plt.legend()
plt.grid()
plt.show()

print(test_df['Case'])
print(future_predictions["yhat"])

from sklearn.metrics import mean_squared_error
from math import sqrt
rmse=sqrt(mean_squared_error(test_df['Case'],future_predictions['yhat']))
print(rmse)

from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error

# Calculating MAE, MSE, and MAPE between test and hybrid columns
mae = mean_absolute_error(test_df['Case'],future_predictions['yhat'])
mse = mean_squared_error(test_df['Case'],future_predictions['yhat'])
mape = mean_absolute_percentage_error(test_df['Case'],future_predictions['yhat'])

mae, mse, mape